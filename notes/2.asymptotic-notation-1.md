# Asymptotic notation

알고리즘의 실행 시간은 컴퓨터가 알고리즘을 실행하는 시간과 컴퓨터 프로그래밍 언어에서 프로그램을 변환하는 컴파일러의 속에 따라 달라진다.

알고리즘 실행 시간을 측정하는데 고려해보아야 하는 아이디어는 다음과 같다.

* 입력 값의 규모와 양에 따라 소요시간을 측정해야한다
* 입력 크기의 증가에 따라 소요시간이 얼마나 빠르게 증가하는지에 대해 파악해야한다. 이것을 **성장률(Rate of growth)** 이라고 부른다.

알고리즘의 실행 시간은 주로 성장률에 중점을 둔다. 이 비율은 이해를 복잡하게 만드는 세부 사항들에 대해 신경을 쓰지 않는다.

이것을 표기하기 위해 **점근표기법(Asymptotic notation)** 을 사용한다. 3가지의 형태가 있다.

* Big-Θ 표기법
* Big-O 표기법
* Big-Ω 표기법

## Big-Θ (Big-Theta) 표기법

어떠한 알고리즘에서

* 루프 한번에 걸리는 시간 = `c_1`
* 알고리즘 입출력 등의 오버헤드 = `c_2`
* 총 루프의 반복 횟수 = `n`

> `c_1`, `c_2`는 컴퓨터의 성능, 컴파일 속도, 몇가지 외부 요인에 연관되어있기 때문에 값을 알 수 없다.

따라서

* `n`번째 반복에 걸리는 시간 = `n` * `c_1`
* 실제 실행시간 = `c_1` * `n` + `c_2`

하지만 상수인 `c_1`과 `c_2`로는 성장률을 알 수 없다.

중요한 것은 선형 검색의 최악의 경우 실행 시간이 배열 크기 `n`처럼 커진다는 것이다.

특정 실행 시간을 `Θ(n)`이라고하면, `n`이 충분히 커지면 실행 시간은 `k_1`과 `k_2`의 상수에 대해 적어도 `k_1 * n`이고 많아야 `k_2 * n`이다. `Θ(n)`을 생각하는 방법은 다음과 같다.

![asymptotic-notation-1](../resources/asymptotic-notation-1.png)

`n`의 값이 작은 경우, 실행 시간이 `k_1 * n` 또는 `k_2 * n`과 어떻게 비교되는지는 신경 쓰지 않는다. 그러나 `n`의 값이 충분히 커지면 실행 시간은 `k_1 * n`과 `k_2 * n` 사이에 존재해야 한다. **이 상수 `k_1`과 `k_2`가있을 때, 실행 시간은 `Θ(n)`이라고 한다**.

### Big-Θ (Big-Theta) 표기법의 특징

* 단지 `n`에만 제한되지 않는다. `n^2`나 `log_2 n` 같이 `n`에 관련된 함수에 대해서도 이를 이용할 수 있다.
* 시간 단위를 고려할 필요가 없다.
* **점근적으로 근접한 한계값**이 있다고 표현한다. **큰 값을 가진 `n`에서만 적용**되며, "근접한 한계값"이라는 말은 **위, 아래로 상수값 내에서 실행 시간을 좁힐 수 있기 때문**이다.

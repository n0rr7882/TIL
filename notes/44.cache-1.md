# Cache

## Cache의 특징

* CPU와 MM의 속도 차이로 인한 CPU 대기 시간을 최소화하기 위하여 **CPU와 MM 사이에 설치하는 High Speed Semiconductor Memory** (보통 CPU 내부에 On-Chip Cache의 형태로 설치)
    * MM보다 Access Speed 높음, Cost 높음 Capacity 낮음
    * Hit Ratio(H) = Cache에 Hit되는 횟수 / 전체 기억장치 Access 횟수
    * Miss ratio = 1 - H
    * Average Memory Access Time(T<sub>a</sub>) = H * T<sub>c</sub> + (1 - H) * T<sub>m</sub>  
    * [예]:
        * Average Memory Access Time: T<sub>c</sub> = 50ns
        * T<sub>m</sub> = 400ns

        H | 70% | 80% | 90% | 95% | 99%
        --|-----|-----|-----|-----|----
        T<sub>a</sub> | 155ns | 120ns | 85ns | 67.5ns | 53.5ns

* Cache Hit Ratio는 Program과 Data의 Locality에 크게 의존
    * Temporal Locality: 최근에 Access된 Data가 가까운 미래에 다시 Access될 가능성이 높음
    * Spatial Locality: 인접하여 저장되어 있는 Data들이 연속적으로 Access될 가능성이 높음
    * Sequential Locality: Branching이 발생하지 않는 한, Instruction들은 저장된 순서대로 인출되어 실행됨

* Cache Design Objectives
    * Hit Ratio의 Maximization = Access Time의 Minimization = Miss에 따른 Delay Time의 최소화
    * Main Memory와 Cache간의 Data Consistency 유지 및 그에 따른 Overhead Minimization

## Hierarchical Cache

* Hierarchical Cache
    * On-Chip Cache를 L1 Cache로 사용하고, Chip 외부에 더 큰 Capacity의 L2 Cache를 설치하는 방식
    * L2는 L1의 Super-Set: L2의 Capacity가 L1보다 크며, L1의 모든 내용이 L2에도 존재
    * L1은 속도가 빠르지만, Capacity가 작기 때문에 L2보다 Hit Ratio는 더 낮음
    * 먼저 L1을 검사하고, 만약 원하는 정보가 L1에 없다면 L2를 검사하며, L2에도 없는 경우에만 Main Memory를 Access
    * 평군 Storage Device Access 시간: T<sub>a</sub> = H * T<sub>C1</sub> + (H<sub>2</sub> - H<sub>1</sub>) * T<sub>C2</sub> + (1 - H<sub>2</sub>) * T<sub>m</sub>
    * [예]
        * L1/L2/MM Access Time: 20/60/200ns
        * L1/L2 Hit Ratio: 0.8/0.95
        * -> T<sub>a</sub> = 0.8 * 20ns + (0.95 - 0.8) * 60ns + (1 - 95) * 200ns = 35ns

## Split Cache

* Split Cache
    * Cache를 **Instruction Cache와 Data Cache**로 분리
    * Instruction Fetch와 Excution 간에 Cache Access 충돌 현상 제거
    * 대부분 고속 Processor(Pentium 개열)에서 사용

## Fetch

* Fetch 방식: MM -> Cache
    * Cache Capacity가 커질수록 Hit Ratio가 높아지지만 Cost가 증가, Access Decoding 및 Data Fetch를 위한 주변 회로가 더 복잡해지기 때문에 Access Time이 다소 길어짐
    * Demand Fetch 방식: 필요한 정보만 인출해오는 방법
    * Prefetch 방식: 앞으로 필요할 것으로 예측되는 정보도 미리 인출, Loca방ity가 높은 경우에 효과가 높음
